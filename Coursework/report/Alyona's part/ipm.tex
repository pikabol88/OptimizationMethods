\documentclass[12pt,a4paper]{article}
\begin{document}
	\subsection{Метод внутренней точки (IP)}
	Метод внутренней точки - это метод позволяющий решать задачи выпуклой оптимизации с условиями, заданными в виде неравенств [8, 1].
	
	Согласно методам внутренней точки, исходную для поиска точку можно выбирать только внутри допустимой области.
	
	Выбор начальной точки поиска осуществляется в зависимости от формулировки задачи. При отсутствии ограничений или их преобразовании к функциям штрафа с внешней точкой начальная точка выбирается произвольно. При наличии ограничений или их преобразовании к функциям штрафа с внутренней точкой начальная точка выбирается внутри допустимой области.
	
	При этом множество точек делится на допустимые и недопустимые в зависимости от ограничений. В свою очередь множество допустимых точек в зависимости от ограничений также делится на граничные и внутренние
	
	\subsubsection{Прямо-двойственный метод внутренней точки}
	Прямо-двойственный метод внутренней точки) оптимизирует прямые и двойственные переменные $(x, \lambda, \mu)$ путем решения линеаризованной возмущенной системы Куна-Таккера [8, 6]:
	\begin{equation}
		\left[
		\begin{matrix}
			\bigtriangledown^2f_0(x) + \sum_{i=1}^{m}	\bigtriangledown^2f_i(x)&  	\bigtriangledown f(x)^T & A^T\\ 
			diag(\lambda)\bigtriangledown f(x) & diag(f(x))  & O\\
			A & O & O
		\end{matrix}
		\right] 
		\left[
		\begin{matrix}
			d_x \\
			d_\lambda \\
			d_\mu \\
		\end{matrix}
		\right] = - 
		\left[
		\begin{matrix}
			\bigtriangledown f_0(x) + 	\bigtriangledown f(x)^T\lambda + A^T\mu \\  	
			diag(\lambda)f(x) + \frac{1}{\tau}\epsilon\\
			Ax - b
		\end{matrix}
		\right] =
	\end{equation}
	\begin{equation}
		= - \left[
		\begin{matrix}
			r_{dual}(x, \lambda, \mu) \\
			r_{center}(x, \lambda, \mu) \\
			r_{primal}(x, \lambda, \mu) \\
		\end{matrix}
		\right] = -r(x, \lambda, \mu).
	\end{equation}
	
	Здесь через $diag(\lambda)$ обозначена диагональная матрица, в которой на диагонали стоит вектор $\lambda$, через $f(x)$ – вектор $[f_1(x), . . . , f_m(x)]^T$, через $\bigtriangledown f(x)$ – матрица производных, в которой в позиции $(ij)$ стоит $\frac{\partial}{\partial x_i}f_i(x)$, а через $e$ – вектор из единиц.
	
	В данном случае величина $||r(x, \lambda, \mu)||$ отражает прогресс итерационного процесса, и на каждой итерации вдоль найденного направления $(d_x, d_\lambda, d_\mu)$ решается задача одномерной минимизации $||r||$. При ее решении с помощью стратегии backtracking значение $\alpha$ уменьшается до выполнения условия [8, 7]:
	\begin{equation}
		||r(x+\alpha d_{x}, \lambda+\alpha d_{\lambda}, \mu+\alpha d_{\mu})|| < (1-\alpha  \rho)||(x,\lambda,\mu)||,
	\end{equation}		
	где $\rho$ – параметр, задаваемый пользователем. Таким образом, получаем следующую общую схему прямодвойственного метода внутренней точки [8, 7]:
	\begin{enumerate}
		\item Выбирается строго допустимая точка $x$, положительный вектор $\lambda$ и произвольный вектор $\mu$. Также выбирается точность оптимизации $\epsilon$, $\epsilon_{feas}$, начальное значение $\tau=\tau_0$, мультипликатор $\upsilon$> 1 и параметры
		стратегии backtracking;
		\item Находится решение $(d_x, d_\lambda, d_\mu)$ СЛАУ (14) для текущего значения $\tau$;
		\item Решается задача одномерной минимизации $	||r(x + \alpha d_x, \lambda +\alpha d_\lambda, \mu + \alpha d_\mu)|| \longrightarrow min, \alpha \geq 0$	с помощью backtracking;
		\item  Если для нового набора $(x, \lambda, \mu)$ выполнено условие $||r_{dual} (x, \lambda, \mu) < \epsilon_{feas}||$, $||r_{primal} (x, \lambda, \mu) < \epsilon_{feas}||$ и $-\lambda^Tf(x)$, то алгоритм заканчивает работу;
		\item Значение $\tau$ устанавливается как $min(\frac{m}{\epsilon}, \tau(\frac{m}{-\lambda^{T}f(x)}))$
		, переход в шагу 2.
	\end{enumerate}
	
	Для прямо-двойственного метода внутренней точки доказана теоретическая сходимость за \textbf{$O(\sqrt{n}\log(\frac{1}{\epsilon}))$} [8, 8]
	итераций. Эта теоретическая оценка худшего числа итераций является наилучшей на сегодняшний день оценкой
	среди всех методов решения задач условной оптимизации. На практике метод внутренней точки сходится за
	константное число итераций, практически не зависящее от размерности задачи (обычно 30–40 итераций). Это
	обстоятельство делает метод особенно привлекательным для использования в случае данных большого объема.
	Метод внутренней точки основан на итерациях Ньютона, обладающих квадратичной скоростью сходимости.
	Поэтому метод внутренней точки позволяет находить решение задачи квадратичного программирования, в том числе, для высокой точности $\epsilon$.
	
	Этот момент является актуальным, например, для разреженных линейных моделей классификации/регрессии, в которых обнуление максимального количества компонент позволяет получать компактные и легко интерпретируемые решающие правила, предъявляющие минимальные требования к вычисляемому набору признаков, необходимому для принятия решений.
\end{document}