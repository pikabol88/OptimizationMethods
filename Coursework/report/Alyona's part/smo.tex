\documentclass[12pt,a4paper]{article}
\begin{document}
	\subsection{Последовательная минимальная Оптимизация (SMO)}
	Sequential minimal optimization (SMO) - алгоритм для решения задачи квадратичного программирования (QP).  SMO широко используется для обучения опорных векторных машин. Публикация алгоритма SMO в 1998 году вызвала большой ажиотаж в сообществе SVM, поскольку ранее доступные методы обучения SVM были намного сложнее и требовали дорогостоящих сторонних решателей QP.
	
	SMO - итерационный алгоритм для решения задачи оптимизации [14]:
	\begin{align*}
		\max_{\alpha}\sum_{i=1}^{n}\alpha_{i}-{\frac{1}{2}}\sum_{i=1}^{n}\sum_{j=1}^{n}y_{i}y_{j}K(x_{i},x_{j})\alpha_{i}\alpha_{j},\\	
		\mbox{при условии:} \qquad
		0\leq \alpha_{i}\leq C, \quad \mbox{для}\quad i=1,2,\ldots ,n,	\\
		\sum_{i=1}^{n}y_{i}\alpha_{i}=0
	\end{align*}\label{eq:smo}
	где $C$ - гиперпараметр SVM, $K(x_i, x_j)$ - функция ядра, а переменные $\alpha_{i}$ являются множителями Лагранжа.
	
	SMO разбивает проблему (\ref{eq:smo}) на серию минимально возможных подзадач, которые затем решаются аналитически. Из-за ограничения линейного равенства, включающего множители Лагранжа $\alpha_{i}$, наименьшая возможная проблема включает два таких множителя. Тогда для любых двух множителей $\alpha_{1}$ и $\alpha_{2}$ , ограничения сокращаются до [14]:
	$$0 \leq \alpha_{1}, \alpha_{2} \leq C,$$
	$$ y_{1}\alpha_{1} + y_{2}\alpha_{2} = k,$$ 
	и эта сокращенная задача может быть решена аналитически: нужно найти минимум одномерной квадратичной функции. $k$ - отрицательное значение суммы остальных членов в ограничении равенства, которое фиксируется на каждой итерации.
	
	Алгоритм работает следующим образом [14]:
	\begin{itemize}
		\item Найти множитель Лагранжа $\alpha_{1}$, который нарушает Условия Каруша — Куна — Таккера (KKT) для задачи оптимизации.
		\item Выбрать второй множитель $\alpha_{2}$ и оптимизировать пару $(\alpha_{1}, \alpha_{2})$.
		\item Повторить шаги 1 и 2 до сходимости.
	\end{itemize}	
	
	Когда все множители Лагранжа удовлетворяют условиям KKT (в пределах заданного пользователем допуска) проблема решена. Хотя этот алгоритм гарантирует сходимость, эвристика используется для выбора пары множителей, чтобы ускорить скорость сходимости. Это очень важно для больших наборов данных, поскольку существует $n(n-1)/2$ возможных вариантов для $\alpha_{i}$ и $\alpha_{j}$.
\end{document}