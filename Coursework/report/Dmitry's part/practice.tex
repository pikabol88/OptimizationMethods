\documentclass[main.tex]{subfiles}
\begin{document}
\subsection{Описание практического задания}
В качестве практического задания рассмотрим распознавание изображений, содержащих цифры. При решении данной задачи будут использоваться различные классификаторы SVM, каждый из которых заключает в себе отличный от других метод решения задачи квадратичного программирования при построении оптимальной гиперплоскости. Таким образом, решая поставленную задачу с помощью классификаторов с разными методами, можно приблизительно сравнить их эффективность. 

Создание разных SVM классификаторов с нуля - достаточно трудоёмкая задача, не рассматриваемая в данной работе. Параметры классификаторов были подобраны так, чтобы обеспечить их сравниваемость, однако это не может в полной мере уберечь от того, что разные классификаторы могут показывать разное поведение, которое обусловлено не только использованием различных методов квадратичного программирования. Для полной чистоты эксперимента необходимо с нуля написать классификаторы SVM и реализации методов квадратичного программирования, а так же составить собственный набор размеченных данных, что выходит за рамки данной работы.

В поставленной задаче использовались следующие классификаторы:
\begin{enumerate}
    \item \textit{Классификатор SVC из пакета svm python-библиотеки sklearn} [9]
        \begin{itemize}
            \item Данный классификатор использует наиболее распространённый в программных реализациях SVM метод решения задачи квадратичного программирования - последовательную минимальную оптимизацию (Sequential Minimal Optimization - SMO)
            \item Программная реализация SMO берётся из известной си-библиотеки libsvm, что положительно влияет на скорость работы классификатора
            \item Классификатор является высокомодифицируемым и крайне распространенным как реализация SVM на python, что говорит о его высоком качестве и возможном превосходстве над менее популярными классификаторами
        \end{itemize}
    \item \textit{Классификатор SupportVectorMachine из библиотеки Machine Learning From Scratch} [10]
        \begin{itemize}
            \item Данный классификатор использует метод внутренней точки (Interior Point - IP), реализация которого берётся из python-библиотеки CVXOPT
            \item Библиотека CVXOPT является одной из самых популярных библиотек оптимизации для python. Классификатор при этом является, скорее, учебным примером, чем быть реально используемым в сложных научных задачах, и может показывать результаты хуже указанных классификаторов
        \end{itemize}
    \item \textit{Классификатор MaxMarginClassifier из статьи журнала Towards Data Science} [11]
        \begin{itemize}
            \item Данный классификатор использует метод последовательного линейно-квадратичного программирования (Sequential Linear-Quadratic Programming - SLQP)
            \item Программная реализация SLQP берётся из python-библиотеки scipy, при этом наблюдаются недостатки, аналогичные использованию предыдущего классификатора
        \end{itemize}
\end{enumerate}

В качестве тестовых данных используется размеченный набор digits из пакета sklearn.datasets, который содержит 10 классов (цифры от 0 до 9 включительно) примерно по 180 образцов на каждый класс. Суммарно получается набор данных из порядка 1800 образцов [12].

Помимо этого, активно используются утилиты из разных пакетов библиотеки sklearn, например, для сбора данных и подсчёта различных метрик. Также в каждом из рассматриваемых классификаторов вектор признаков формируется посредством метода локальных бинарных шаблонов LBP.

В качестве метрики качества предсказаний используется accuracy score из пакета sklearn.metrics, который считает отношение числа верных предсказаний к общему числу всех предсказаний [13].

Поскольку SVM в первую очередь является методом бинарной классификации, а набор данных содержит в себе 10 размеченных классов, то в качестве дополнительного эксперимента проводится переразметка данных под 2 класса и распознавание по ним. Создаются два класса цифр: $x \leq 4$ и $x \geq 5$, и все существующие метки классов $[0, 4]$ превращаются в метку класса 0, а метки классов $[5, 9]$ в метку класса 1. Изображения в наборе данных при этом не изменяются. Обучение и предсказание происходит на основе уже переразмеченных классов.

Эксперимент проводится последовательно по всем трём методам (SMO, IP, SLQP) с разными наборами меток классов (10 классов или 2 класса). Для надёжности каждый эксперимент повторяется 5 раз. Таким образом, получается $3 * 2 * 5 = 30$ независимых экспериментов.

По итогам практического эксперимента, составляется таблица результатов. Дополнительно по значениям из таблицы считаются среднее, медианное и максимальное значения accuracy score для каждого метода по каждому из наборов меток.

\subsection{Результаты практического задания}
Ниже представлены таблицы с результатами:

\begin{table}[H]
    \centering
    \begin{tabular}{|l||c|c|}
        \hline
        & 10 classes & 2 classes \\\hline\hline
        1 & 0.988889 & 0.995556 \\\hline
        2 & 0.993333 & 0.995556 \\\hline
        3 & 0.991111 & 0.991111 \\\hline
        4 & 0.993333 & 1 \\\hline
        5 & 0.986667 & 0.991111 \\\hline
        Mean & 0.990667 & 0.994667 \\\hline
        Median & 0.991111 & 0.995556 \\\hline
        Max & 0.993333 & 1 \\\hline
    \end{tabular}
    \caption{Метод SMO}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|l||c|c|}
        \hline
        & 10 classes & 2 classes \\\hline\hline
        1 & 0.0644444 & 0.488889 \\\hline
        2 & 0.0866667 & 0.504444 \\\hline
        3 & 0.0866667 & 0.451111 \\\hline
        4 & 0.108889 & 0.48 \\\hline
        5 & 0.1 & 0.506667 \\\hline
        Mean & 0.0893333 & 0.486222 \\\hline
        Median & 0.0866667 & 0.488889 \\\hline
        Max & 0.108889 & 0.506667 \\\hline
    \end{tabular}
    \caption{Метод IP}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|l||c|c|}
        \hline
        & 10 classes & 2 classes \\\hline\hline
        1 & 0.111111 & 0.473333 \\\hline
        2 & 0.0911111 & 0.542222 \\\hline
        3 & 0 & 0.513333 \\\hline
        4 & 0.0911111 & 0.522222 \\\hline
        5 & 0.122222 & 0.482222 \\\hline
        Mean & 0.0831111 & 0.506667 \\\hline
        Median & 0.0911111 & 0.513333 \\\hline
        Max & 0.122222 & 0.542222 \\\hline
    \end{tabular}
    \caption{Метод SLQP}
\end{table}

По результатам эксперимента видно, что лучшее качество на рассмотренной задаче показывает метод SMO с точностью, близкой к 1, а классификаторы на основе методов IP и SLQP показывают качество заметно ниже. Сравнивая методы IP и SLQP, классификатор на основе последнего демонстрирует точность несколько лучше по всем параметрам нежели первый.

Такое сильное различие в точности может быть обосновано тем, что классификатор на основе SMO является программным продуктом высокого качества, используемым в серьёзных научных задачах, а классификаторы, основанные на методах IP и SLQP являются учебными примерами и не предназначены для настоящих задач. Помимо этого, выбранный набор данных содержит изображения очень низкого качества - 8х8 пикселей, а также изображения часто зашумлены - имеют много бесполезной информации вокруг объекта распознавания. Всё это в совокупности может иметь сильное негативное влияние на качество распознавания менее профессиональными классификаторами.
\end{document}